{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPaMHZ/ntzX6HPBr+kaqfH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/318245915/Reconocimiento-de-Patrones-y-Aprendizaje-Automatizado/blob/main/Proyecto_Final_RDPYAA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema de recomendación de películas o música basado en preferencias y comportamientos pasados de los usuarios."
      ],
      "metadata": {
        "id": "46vmWoaVlrhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtención y preprocesamiento de datos."
      ],
      "metadata": {
        "id": "lVV7q3WhlywK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Importación de librerías: Importamos las librerías necesarias para manipulación de datos (pandas), división del dataset (train_test_split), y normalización de datos (StandardScaler).\n",
        "2.   Cargar los datos: Leemos los archivos ratings.csv y movies.csv que contienen las calificaciones y la información de las películas, respectivamente.\n",
        "3. Combinar los datos: Unimos los datasets de calificaciones y películas en base al movieId para tener un dataset completo con las calificaciones y los títulos de las películas.\n",
        "4. División de datos: Dividimos el dataset combinado en conjuntos de entrenamiento y prueba.\n",
        "5. Normalización de calificaciones: Normalizamos las calificaciones para mejorar el rendimiento del modelo."
      ],
      "metadata": {
        "id": "_2k5RzxVmGLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aENyEk84ld_f",
        "outputId": "a28760bf-c7f4-487d-b6e9-02e60641bee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n",
            "   userId  movieId  rating   timestamp             title  \\\n",
            "0       1        1     4.0   964982703  Toy Story (1995)   \n",
            "1       5        1     4.0   847434962  Toy Story (1995)   \n",
            "2       7        1     4.5  1106635946  Toy Story (1995)   \n",
            "3      15        1     2.5  1510577970  Toy Story (1995)   \n",
            "4      17        1     4.5  1305696483  Toy Story (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "2  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "3  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "4  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "Tamaño del conjunto de entrenamiento: (80668, 6)\n",
            "Tamaño del conjunto de prueba: (20168, 6)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "!pip install scikit-surprise\n",
        "\n",
        "# Cargar los datos de MovieLens\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "movies = pd.read_csv('movies.csv')\n",
        "\n",
        "# Verificar las primeras filas de los datasets\n",
        "print(ratings.head())\n",
        "print(movies.head())\n",
        "\n",
        "# Unir las calificaciones con los títulos de las películas\n",
        "data = pd.merge(ratings, movies, on='movieId')\n",
        "\n",
        "# Mostrar algunas filas del dataset combinado\n",
        "print(data.head())\n",
        "\n",
        "# Preprocesar los datos\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar las calificaciones\n",
        "scaler = StandardScaler()\n",
        "train_data['rating'] = scaler.fit_transform(train_data[['rating']])\n",
        "test_data['rating'] = scaler.transform(test_data[['rating']])\n",
        "\n",
        "# Mostrar el tamaño de los conjuntos de entrenamiento y prueba\n",
        "print(f'Tamaño del conjunto de entrenamiento: {train_data.shape}')\n",
        "print(f'Tamaño del conjunto de prueba: {test_data.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diseño y entrenamiento del Modelo de Filtrado Colaborativo"
      ],
      "metadata": {
        "id": "YMxeTJudmEUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Configuración del lector: Utilizamos Reader de Surprise para especificar la escala de calificaciones.\n",
        "2. Conversión de datos: Convertimos el DataFrame de entrenamiento en un formato que Surprise pueda manejar.\n",
        "3. Definición del modelo: Utilizamos la técnica de descomposición en valores singulares (SVD) para el filtrado colaborativo.\n",
        "4. Validación cruzada: Evaluamos el modelo utilizando validación cruzada para obtener métricas de rendimiento.\n",
        "5. Entrenamiento final: Entrenamos el modelo en el conjunto completo de entrenamiento.\n"
      ],
      "metadata": {
        "id": "N6pu-NRgmgGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Configurar el lector para Surprise\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "\n",
        "# Convertir el DataFrame en un formato adecuado para Surprise\n",
        "data = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Definir el modelo de filtrado colaborativo utilizando SVD\n",
        "model = SVD()\n",
        "\n",
        "# Entrenar y evaluar el modelo utilizando validación cruzada\n",
        "cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Entrenar el modelo en el conjunto completo de entrenamiento\n",
        "trainset = data.build_full_trainset()\n",
        "model.fit(trainset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdS0bG8vmr_b",
        "outputId": "85300143-5134-4c25-9c3e-a84bb3b777ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    1.1258  1.1139  1.1051  1.1086  1.1146  1.1136  0.0070  \n",
            "MAE (testset)     0.8248  0.8213  0.8130  0.8081  0.8180  0.8171  0.0059  \n",
            "Fit time          2.44    1.17    1.18    1.18    1.14    1.42    0.51    \n",
            "Test time         0.10    0.19    0.09    0.09    0.08    0.11    0.04    \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x78c749d32080>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar el modelo"
      ],
      "metadata": {
        "id": "0RELZpStnuYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Conversión del conjunto de prueba: Convertimos el conjunto de prueba en un formato que Surprise pueda manejar.\n",
        "2. Predicciones: Utilizamos el modelo entrenado para realizar predicciones sobre el conjunto de prueba.\n",
        "3. Evaluación: Calculamos el error cuadrático medio (RMSE) y el error absoluto medio (MAE) para evaluar el rendimiento del modelo.\n"
      ],
      "metadata": {
        "id": "W4qR_hQHnyUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy\n",
        "\n",
        "# Convertir el conjunto de prueba en el formato adecuado para Surprise\n",
        "test_data = Dataset.load_from_df(test_data[['userId', 'movieId', 'rating']], reader)\n",
        "testset = test_data.build_full_trainset().build_testset()\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "predictions = model.test(testset)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "rmse = accuracy.rmse(predictions)\n",
        "mae = accuracy.mae(predictions)\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f'MAE: {mae}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H96zI60tn7JU",
        "outputId": "99a52838-7e9b-4315-f505-73f797bf902f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.1060\n",
            "MAE:  0.8111\n",
            "RMSE: 1.1060396051868582\n",
            "MAE: 0.8111296925774766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desplegar el modelo\n"
      ],
      "metadata": {
        "id": "alNEWhMyn94y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Importación de Flask: Importamos Flask para crear la API.\n",
        "2. Creación de la aplicación: Creamos una instancia de Flask.\n",
        "3. Definición del endpoint: Definimos un endpoint /recommend que acepta el user_id como parámetro de consulta.\n",
        "4. Obtención de recomendaciones: Para el usuario especificado, calculamos las predicciones de calificación para todas las películas no vistas y seleccionamos las 10 mejores recomendaciones.\n",
        "5. Devolución de resultados: Convertimos las recomendaciones en formato JSON y las devolvemos al cliente.\n",
        "6. Ejecución de la aplicación: Ejecutamos la aplicación Flask en modo de depuración.\n",
        "\n"
      ],
      "metadata": {
        "id": "B8HURNOpoFlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/recommend', methods=['GET'])\n",
        "def recommend():\n",
        "    user_id = int(request.args.get('user_id'))\n",
        "    # Obtener las predicciones para todas las películas que el usuario no ha calificado\n",
        "    all_movie_ids = data.build_full_trainset().all_items()\n",
        "    predictions = [model.predict(user_id, movie_id) for movie_id in all_movie_ids]\n",
        "    # Ordenar las predicciones por calificación estimada\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    # Seleccionar las top 10 recomendaciones\n",
        "    top_recommendations = predictions[:10]\n",
        "    # Convertir las recomendaciones a un formato legible\n",
        "    recommendations = [{'movieId': pred.iid, 'estimated_rating': pred.est} for pred in top_recommendations]\n",
        "    return jsonify(recommendations)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJRpTV3RoAec",
        "outputId": "5e79fab9-d07c-47ae-9181-49cb61ec2790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}